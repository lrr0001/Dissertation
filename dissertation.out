\BOOKMARK [0][-]{titlePage.0}{Title Page}{}% 1
\BOOKMARK [0][-]{Doc-Start}{Acknowledgments}{}% 2
\BOOKMARK [0][-]{TOC.0}{Table of Contents}{}% 3
\BOOKMARK [0][-]{chapter*.1}{List of Tables}{}% 4
\BOOKMARK [0][-]{chapter*.2}{List of Figures}{}% 5
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 6
\BOOKMARK [1][-]{section.1.1}{Dictionaries and Dictionary Learning}{chapter.1}% 7
\BOOKMARK [2][-]{subsection.1.1.1}{Convolutional Dictionaries}{section.1.1}% 8
\BOOKMARK [1][-]{section.1.2}{Convolutional Neural Networks}{chapter.1}% 9
\BOOKMARK [1][-]{section.1.3}{Multi-Layer Dictionaries}{chapter.1}% 10
\BOOKMARK [1][-]{section.1.4}{Contributions and Organization of Dissertation}{chapter.1}% 11
\BOOKMARK [0][-]{chapter.2}{Learning Dictionaries for Multi-Channel Signals}{}% 12
\BOOKMARK [1][-]{section.2.1}{Introduction}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.2}{Dictionary Types}{chapter.2}% 14
\BOOKMARK [1][-]{section.2.3}{Pursuit and Sparse Coding}{chapter.2}% 15
\BOOKMARK [1][-]{section.2.4}{ADMM}{chapter.2}% 16
\BOOKMARK [1][-]{section.2.5}{Applying ADMM to the Sparse Coding Problem}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.5.1}{Exploiting Dictionary Structure for the Inverse Problem}{section.2.5}% 18
\BOOKMARK [1][-]{section.2.6}{Sparse Coding for Multi-Channel Signals: Alternatives to My Novel Approach}{chapter.2}% 19
\BOOKMARK [1][-]{section.2.7}{A Novel Approach to Sparse Coding: ADMM with Low-Rank Updates}{chapter.2}% 20
\BOOKMARK [2][-]{subsection.2.7.1}{Low-Rank Updates}{section.2.7}% 21
\BOOKMARK [2][-]{subsection.2.7.2}{Handling Dictionary Normalization}{section.2.7}% 22
\BOOKMARK [2][-]{subsection.2.7.3}{Dictionary Updates}{section.2.7}% 23
\BOOKMARK [1][-]{section.2.8}{Conclusion}{chapter.2}% 24
\BOOKMARK [0][-]{chapter.3}{Learning Multi-Layer Dictionaries}{}% 25
\BOOKMARK [1][-]{section.3.1}{Introduction}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.2}{Literature Review}{chapter.3}% 27
\BOOKMARK [1][-]{section.3.3}{Multi-Layer ADMM with Low-Rank Updates}{chapter.3}% 28
\BOOKMARK [2][-]{subsection.3.3.1}{Coefficients Update Equation}{section.3.3}% 29
\BOOKMARK [2][-]{subsection.3.3.2}{Proximal Updates}{section.3.3}% 30
\BOOKMARK [2][-]{subsection.3.3.3}{Dual Updates}{section.3.3}% 31
\BOOKMARK [1][-]{section.3.4}{Summary}{chapter.3}% 32
\BOOKMARK [0][-]{chapter.4}{JPEG Artifact Removal}{}% 33
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 34
\BOOKMARK [1][-]{section.4.2}{JPEG Algorithm}{chapter.4}% 35
\BOOKMARK [1][-]{section.4.3}{Literature Review}{chapter.4}% 36
\BOOKMARK [1][-]{section.4.4}{Modelling Compressed JPEG Images}{chapter.4}% 37
\BOOKMARK [1][-]{section.4.5}{Handling Quantization}{chapter.4}% 38
\BOOKMARK [1][-]{section.4.6}{Experiments}{chapter.4}% 39
\BOOKMARK [2][-]{subsection.4.6.1}{Experiment Setup}{section.4.6}% 40
\BOOKMARK [2][-]{subsection.4.6.2}{Results}{section.4.6}% 41
\BOOKMARK [1][-]{section.4.7}{Conclusion}{chapter.4}% 42
\BOOKMARK [0][-]{chapter.5}{Practical Considerations Concerning Tensorflow}{}% 43
\BOOKMARK [1][-]{section.5.1}{Boundary Handling}{chapter.5}% 44
\BOOKMARK [1][-]{section.5.2}{Removing Low-Frequency Signal Content}{chapter.5}% 45
\BOOKMARK [2][-]{subsection.5.2.1}{JPEG Artifact Removal}{section.5.2}% 46
\BOOKMARK [1][-]{section.5.3}{Tensorflow and Keras}{chapter.5}% 47
\BOOKMARK [2][-]{subsection.5.3.1}{Why Not Use Gradient Tape and TensorFlow-1-Stye Code?}{section.5.3}% 48
\BOOKMARK [2][-]{subsection.5.3.2}{Shared Weights Between Layers}{section.5.3}% 49
\BOOKMARK [2][-]{subsection.5.3.3}{Custom Partial Gradients}{section.5.3}% 50
\BOOKMARK [2][-]{subsection.5.3.4}{Updating TensorFlow Variables After Applying Gradients}{section.5.3}% 51
\BOOKMARK [2][-]{subsection.5.3.5}{The Perils of Using Built-In Functions for Complex Tensors and Arrays}{section.5.3}% 52
\BOOKMARK [0][-]{Appendix.1.A}{Experimental Equipment}{}% 53
\BOOKMARK [0][-]{Appendix.1.B}{Data Processing}{}% 54
\BOOKMARK [0][-]{chapter*.7}{References}{}% 55
\BOOKMARK [0][-]{chapter*.8}{Vita}{}% 56
