\chapter{Practical Considerations}
\section{Boundary Handling}
Convolution and circular convolution can produce boundary effects that can impact performance. In the JPEG compression artifact removal chapter, $\mW$ is defined as the function producing $8 \times 8$ block DCT coefficients from an RGB image. However, to mitigate boundary effects this should in practice also include cropping the image. This allows $\mD_1\vx_1$ to reconstruct the signal outside of the measured space (similar to the "boundary masking" in \cite{wohlberg2016boundary}, but with the constraint and objective term swapped). Initialization is important however \cite{DBLP:journals/corr/WohlbergR17}. Reflecting across the boundary is a much better initialization approach than zeros, but if using patches, actual (compressed image) measurements would provide an even better initialization. For the experiments in chapter $4$, I use these compressed image measurements.
\section{Removing Low-Frequency Signal Content}
Convolutional dictionary models tend to struggle with low-frequency signal content, so ideally steps should be taken to avoid representing it with the dictionary model. Tikhonov regularization is a straight-forward means to remove low-frequency content \cite{garcia2018convolutional}:
\begin{equation}
\vs_{\text{smth}} = \arg\min_{\vx} \frac{1}{2}\|\vs - \vx\|_2^2 + \lambda\|\sum_i \mG_i\vx\|_2^2
\end{equation}
where $\mG_i$ computes a discrete gradient in the $i$th direction. This has a closed form solution and can be easily solved in frequency domain.
\subsection{JPEG Artifact Removal}
Tikhonov regularization can struggle with block artifacts from JPEG compression. Rather than smooth the compressed JPEG image itself, it is better to solve for a smoothed version of a signal that compresses to the compressed JPEG image. This problem can be solved using ADMM.
\begin{equation}
\minimize_{\vx,\vv} \frac{1}{2}\|\vv - \vx\|_2^2 + \lambda\|\sum_i \mG_i\vx\|_2^2 + \indicator_{\{\mQ(\mW\vv) - \vs = \vzero\}}
\end{equation}

There are no constraints, so no dual variables are needed. Just alternate between a Tikhonov update for $\vx$ and an update for $\vv$ that closely resembles the $\vv$ update from the last chapter.
Handling the cases in pointwise fashion, define function $h$ as the following clipping operation:
%
\begin{equation}
\operatorname{h}(\vx) = \mW(\vv - \vx) = \begin{cases} \vs + \frac{\vq}{2} - \mW(\vx) & \mW(\vx) > \vs + \frac{\vq}{2} \\ \vs - \frac{\vq}{2} - \mW(\vx) & \mW(\vx) < \vs - \frac{\vq}{2} \\ \vzero & \text{otherwise}
\end{cases}
\end{equation}
%
Then,
\begin{equation}
\vv = \vx + \mW^{\dagger}\operatorname{h}(\vx)
\end{equation}

In the final update for $\vx$, it may help to increase $\lambda$. This will make the resulting smoothed image slightly more smooth, which allows the rough signal component to keep more information content from the image to compute better coefficients.

\section{Inverse Representation Drift}
Rank-$1$ Hermitian updates to a Cholesky factorization or other inverse representation can be computed in quadratic time. However, these algorithms compute the new inverse representation from the old one, compounding precision error. Over the course of many iterations, the inverse representation will become less and less accurate. It is necessary to occasionally recompute the inverse representation in cubic time, to mitigate the impact of precision errors.  One method to determine when to recompute the inverse representation is to measure the error of the inverse function in reconstructing a random set of vectors $\hat{\vu}$, and recompute the inverse representation in cubic time when the error $\epsilon$ exceeds a threshold.
%
\begin{equation}
\epsilon = \max_i \|(\rho\mId + (\hat{\mD}\mR)^T\hat{\mD}\mR)^{-1}(\rho\hat{\vu}_i + (\hat{\mD}\mR)^T\hat{\mD}\mR\hat{\vu}_i\|_{\infty}
\end{equation} 

\section{Tensorflow and Keras}
Most of the computations for my research rely on TensorFlow version 2.3.1 and version 2.4.1 \cite{tensorflow}, a Python library for machine learning specializing in building models with differentiable, parameterizable composite functions and learning model parameters using gradient descent or other gradient-based optimization methods. TensorFlow is a common platform for researchers and developers working on artificial neural networks, and there are many tutorials and examples freely available online, so I will not replicate that work here. This chapter section the reader already has some familiarity with TensorFlow and Keras \cite{keras} (a high-level library inside TensorFlow). The goal of this section is to provide the reader with the tools and workarounds to be able to replicate my work without resorting to hacking things together with gradient tape and/or TensorFlow-1-style code.

\subsection{Why Not Use Gradient Tape and TensorFlow-1-Style Code?}
Keras offers a high-level environment. Code written in Keras's framework is easier to integrate with other work. Gradient tape is great for hacking something together or debugging, but promotes styles of coding that are less readable, less maintainable, and less portable. Keras also has a lower learning curve than the broader TensorFlow library.
\TODO{I should write more for this section or possibly remove it. Might help to read through Keras documentation and endorsements to see why they think it's necessary.}


\subsection{Shared Weights Between Layers}
Trainable TensorFlow variables declared outside of any Keras layer will not be automatically added to a Keras model's list of trainable variables. In most cases, this limitation is not a problem; it is intuitive to declare a layer's weights inside that layer. However, sometimes the same variable is needed in multiple distinct layers. To include a variable in the model's trainable variables, it is sufficient to declare the variable in one layer and pass the variable (or the layer it was initialized in) as an input argument to the \_\_init\_\_ function of the other layers that share that variable. This will work even if the Keras model does not use the layer that declared the variable. Keras users should be careful when combining Keras classes with non-Keras classes, as certain class structures can prevent Keras from detecting some trainable variables.\footnote{If a Keras layer instantiates a non-Keras class that instantiates a Keras class that creates a trainable variable, Keras will fail to detect the trainable variable, and the variable will not be updated during training or saved when the model weights are saved.}

\subsection{Custom Partial Gradients}
TensorFlow offers a well-documented means of replacing TensorFlow's gradient computations of an operation with specified custom gradient computations. However, if the operation involves multiple tensors that are inputs or trainable variables, the standard approach replaces all the gradients with custom gradients. If TensorFlow's gradient computations are sufficient for some tensors but not others, a workaround is necessary. This workaround is best explained by example.

Suppose the operation is the following:


\begin{code}
z = f(x,y)
\end{code}

for which the standard TensorFlow gradient computations of $f$ are desired in respect to $x$, but the custom gradient computations desired in respect to $y$ are specified in function $g(\nabla_z \L)$. This can be rewritten as the following:

\begin{code}
@tf.custom_gradient
def h(z,y):
    def grad_fun(grad):
        return (tf.identity(grad),g(grad))
    return z,grad_fun
z = f(x,tf.stop_gradient(y))
z = h(z,y)
\end{code}

The function $h$ does nothing on the forward pass, but in the backward pass computes the custom gradient in respect to $y$ as intended.

\subsection{Updating TensorFlow Variables After Applying Gradients}
To update TensorFlow Variables after applying gradients, it is necessary to track which variables are affected and what their corresponding update functions are. To accomplish this, I store the update functions in a Python dictionary using variable names as the dictionary keys. This Python dictionary needs to be widely accessible so that layers can add update functions when they are initialized; a simple way to do this is to make the update function Python dictionary a class attribute. The keys need to be unique, but TensorFlow variable names can conflict. It is easy to avoid this problem by checking for conflicts before adding a new update function.

\begin{code}
class PostPrc:
    update = {}
    def add_update(varName,update_fun):
        assert varName not in PostPrc.update
        PostPrc.update[varName] = update_fun
\end{code}


In the standard Keras training paradigm, models are trained using the fit function, a method in the Keras model object. The fit function calls the function train\_step, where gradients are applied.  To update TensorFlow Variables after gradients are applied in Tensorflow 2.3.1 on a CPU, train\_step is the function to modify. The only change that needs to be made is adding a function call to all update functions that correspond to the model's list of trainable variables.

\begin{code}
class Model_subclass(tf.keras.Model):
    def train_step(self,data):
        trainStepOutputs = tf.keras.Model.train_step(self,data)
        update_ops = []
        for tv in self.trainable_variables:
            if tv.name in PostPrc.update:
                PostPrc.update[tv.name]()
        return trainStepOutputs
\end{code}

Changes to Tensorflow variables in the update function must use the assign command (or its variants: assign\_add, assign\_sub, ect). Otherwise, TensorFlow will detect that computations lie outside of its computational graph and throw an error. Note that using the assign command on Python variables that are not TensorFlow variables will produce some very cryptic error messages, so be sure to use the assign command correctly. If the value change of one TensorFlow variable depends on the value of another TenorFlow variable value pre-update, it may be necessary to use the Tensorflow control\_dependencies command to get TensorFlow to track that dependency. TensorFlow has a useful tool called TensorBoard that helps visualize TensorFlow's dependencies, but a workaround is required to use TensorBoard on update functions that are called after applying gradients. To use TensorBoard to visualize dependencies in an update function, temporarily call the update function in the layer's call method, use TensorBoard to verify all necessary dependencies are being tracked, then remove the update function call from the layer's call method.

However, in Tensorflow 2.4.1 on a GPU, the above method fails. The PostPrc class is still fine, but the update functions must be instead be called using Keras callbacks.
\begin{code}
class PostPrcCallback(keras.callbacks.Callback,PostPrc):
    def on_train_begin(self,logs):
        logs = logs or {}
        self.update = []
        for tv in self.model.trainable_variables:
            if tv.name in PostPrc.update:
                self.update.append(PostPrc.update[tv.name])

    def on_batch_end(self, epoch, logs=None):
        logs = logs or {}

        for an_update in self.update:
            an_update()

        for k, v in logs.items():
            self.history.setdefault(k, []).append(v)
\end{code}

\subsection{The Perils of Using Built-In Functions for Complex Tensors and Arrays}
Complex numbers are not as frequently used by researchers and practitioners, and many tools and platforms fail on complex cases.  Tensorflow's assign\_add command can fail on the GPU, so users should use the assign command instead. It is necessary in some cases to split complex variables into their real and imaginary components to avoid GPU errors. 
The TensorFlow Probability version 0.11.1 \cite{tensorflowprobability} is an extension of TensorFlow mostly used for probabilistic models. The library contains a Cholesky update function, but the function does not properly handle complex inputs. To compute Cholesky updates for complex inputs, modifications of this code are necessary. Similarly, the Randomized SVD algorithm in the Python scikit-learn library does not properly handle complex inputs.

Errors like these are fairly common, so when dealing with complex data, researchers and practitioners should carefully verify that the function libraries they rely on are properly handling complex numbers. It is also important for code to be highly modularized, because if an error does not occur until computations on the computational graph or saving weights, platforms may not be able to identify where in the code the error is coming from, and error messages can be cryptic or even wrong.
